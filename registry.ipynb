{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "from model_registry import ModelRegistry, utils\n",
    "\n",
    "def infer_model_format(uri):\n",
    "    \"\"\"Infer model format from file extension.\"\"\"\n",
    "    ext = os.path.splitext(uri)[1].lower()\n",
    "    return {\n",
    "        \".onnx\": \"onnx\",\n",
    "        \".pkl\": \"sklearn\",\n",
    "        \".pt\": \"pytorch\",\n",
    "        \".joblib\": \"sklearn\",\n",
    "        \".h5\": \"keras\",\n",
    "        \".sav\": \"sklearn\"\n",
    "    }.get(ext, \"unknown\")\n",
    "\n",
    "def is_huggingface_model(uri_or_repo):\n",
    "    \"\"\"Detect if string looks like a Hugging Face model repo.\"\"\"\n",
    "    return (\n",
    "        isinstance(uri_or_repo, str)\n",
    "        and \"/\" in uri_or_repo\n",
    "        and not uri_or_repo.startswith((\"http\", \"s3://\", \"minio://\", \"/\"))\n",
    "    )\n",
    "\n",
    "def register_model_allinone(\n",
    "    registry_url,\n",
    "    model_name,\n",
    "    uri_or_repo,\n",
    "    author=None,\n",
    "    storage_key=None,\n",
    "    model_format=None,\n",
    "    description=None,\n",
    "    version=None,\n",
    "    metadata=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Universal model registration for MinIO, S3, HF, public URLs, and local files.\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize client\n",
    "    registry = ModelRegistry(registry_url, author=author)\n",
    "\n",
    "    # Step 2: Register Hugging Face model (repo ID style)\n",
    "    if is_huggingface_model(uri_or_repo):\n",
    "        return registry.register_huggingface_model(\n",
    "            model_name,\n",
    "            repo_id=uri_or_repo,\n",
    "            description=description,\n",
    "            version=version,\n",
    "            metadata=metadata or {}\n",
    "        )\n",
    "\n",
    "    # Step 3: Auto-infer model format if not given\n",
    "    if not model_format:\n",
    "        model_format = infer_model_format(uri_or_repo)\n",
    "\n",
    "    # Step 4: Convert MinIO/S3 URIs using storage key\n",
    "    if uri_or_repo.startswith(\"minio://\") and storage_key:\n",
    "        uri_or_repo = utils.s3_uri_from(uri_or_repo.replace(\"minio://\", \"\"), storage_key)\n",
    "    elif uri_or_repo.startswith(\"s3://\") and storage_key:\n",
    "        uri_or_repo = utils.s3_uri_from(uri_or_repo.replace(\"s3://\", \"\"), storage_key)\n",
    "\n",
    "    # Step 5: Register model\n",
    "    return registry.register_model(\n",
    "        model_name,\n",
    "        uri=uri_or_repo,\n",
    "        model_format=model_format,\n",
    "        description=description,\n",
    "        version=version,\n",
    "        storage_key=storage_key,\n",
    "        metadata=metadata or {}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_model_allinone(\n",
    "    registry_url=\"https://your-registry.com\",\n",
    "    model_name=\"my-cool-model\",\n",
    "    uri_or_repo=\"minio://mlpipeline/models/my-model.onnx\",\n",
    "    storage_key=\"mlpipeline\",\n",
    "    metadata={\n",
    "        \"task\": \"classification\",\n",
    "        \"framework\": \"onnx\",\n",
    "        \"team\": \"mlops\",\n",
    "        \"dataset\": \"imagenet\"\n",
    "    }\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
